{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcIDdPReCq1W",
        "outputId": "c061eaf9-121b-401c-d211-74853af6b498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Epoch 1, Loss: 8.553, Accuracy: 83.98%\n",
            "Epoch 2, Loss: 2.831, Accuracy: 95.58%\n",
            "Epoch 3, Loss: 0.995, Accuracy: 98.34%\n",
            "Epoch 4, Loss: 0.729, Accuracy: 98.90%\n",
            "Epoch 5, Loss: 0.115, Accuracy: 99.86%\n",
            "Test Accuracy: 96.67%\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "# ✅ Dataset path\n",
        "data_dir = \"/content/drive/MyDrive/Waste Detection - Classification.v3i.folder\"\n",
        "\n",
        "# ✅ Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# ✅ Load datasets\n",
        "train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"train\"), transform=transform)\n",
        "valid_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"valid\"), transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"test\"), transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ✅ Load pretrained VGG16 model\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "weights = VGG16_Weights.DEFAULT\n",
        "model = vgg16(weights=weights)\n",
        "\n",
        "# ✅ Replace classifier for 2-class classification\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n",
        "\n",
        "# ✅ Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# ✅ Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "num_epochs = 5\n",
        "\n",
        "# ✅ Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.3f}, Accuracy: {acc:.2f}%\")\n",
        "\n",
        "# ✅ Evaluation on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "\n",
        "# ✅ Function to visualize predictions from dataset\n",
        "def predict_from_dataset(dataset, model, transform, class_names, num_images=5):\n",
        "    model.eval()\n",
        "    indices = random.sample(range(len(dataset)), num_images)\n",
        "\n",
        "    for idx in indices:\n",
        "        image, label = dataset[idx]\n",
        "        input_tensor = image.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            predicted_class = class_names[predicted.item()]\n",
        "            true_class = class_names[label]\n",
        "\n",
        "        plt.imshow(F.to_pil_image(image))\n",
        "        plt.title(f\"Predicted: {predicted_class} | Actual: {true_class}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# ✅ Function to predict any custom image\n",
        "def predict_custom_image(image_path, model, transform, class_names):\n",
        "    model.eval()\n",
        "\n",
        "    # Load and preprocess image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        predicted_class = class_names[predicted.item()]\n",
        "\n",
        "    # Show image with prediction\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Predicted: {predicted_class}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "# ✅ Your dataset path\n",
        "data_dir = \"/content/drive/MyDrive/Waste Detection - Classification.v3i.folder\"\n",
        "\n",
        "# ✅ Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# ✅ Load datasets (make sure train/valid/test folders exist)\n",
        "train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"train\"), transform=transform)\n",
        "valid_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"valid\"), transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"test\"), transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ✅ Load pretrained VGG16 model\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "weights = VGG16_Weights.DEFAULT\n",
        "model = vgg16(weights=weights)\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "num_epochs = 5\n",
        "\n",
        "# ✅ Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.3f}, Accuracy: {acc:.2f}%\")\n",
        "\n",
        "# ✅ Test the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "# ✅ Class names from training data\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "\n",
        "# ✅ Webcam capture and real-time prediction (Colab only)\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# ✅ Function to capture image from webcam\n",
        "def capture_image():\n",
        "    js = Javascript('''\n",
        "    async function takePhoto() {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = '📸 Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      stream.getTracks().forEach(track => track.stop());\n",
        "      div.remove();\n",
        "\n",
        "      return canvas.toDataURL('image/jpeg');\n",
        "    }\n",
        "    takePhoto();\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js(\"takePhoto()\")\n",
        "    header, encoded = data.split(\",\", 1)\n",
        "    binary = b64decode(encoded)\n",
        "    img_array = np.frombuffer(binary, dtype=np.uint8)\n",
        "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "    return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# ✅ Capture image\n",
        "image = capture_image()\n",
        "input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    predicted_class = class_names[predicted.item()]\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Predicted: {predicted_class}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eCNmP1XRw9XK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "outputId": "8d850180-59b5-4488-aab1-86fa191ca7f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 128MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.010, Accuracy: 87.85%\n",
            "Epoch 2, Loss: 2.147, Accuracy: 96.41%\n",
            "Epoch 3, Loss: 1.197, Accuracy: 98.20%\n",
            "Epoch 4, Loss: 0.827, Accuracy: 98.90%\n",
            "Epoch 5, Loss: 0.893, Accuracy: 98.34%\n",
            "Test Accuracy: 94.44%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto() {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = '📸 Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "\n",
              "      stream.getTracks().forEach(track => track.stop());\n",
              "      div.remove();\n",
              "\n",
              "      return canvas.toDataURL('image/jpeg');\n",
              "    }\n",
              "    takePhoto();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "NotAllowedError: Permission denied",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-089a317db69b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m# ✅ Capture image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-089a317db69b>\u001b[0m in \u001b[0;36mcapture_image\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m     ''')\n\u001b[1;32m    130\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"takePhoto()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: NotAllowedError: Permission denied"
          ]
        }
      ]
    }
  ]
}